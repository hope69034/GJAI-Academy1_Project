{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15794,"status":"ok","timestamp":1661299860592,"user":{"displayName":"ᄋᄋ","userId":"14927427201019733620"},"user_tz":-540},"id":"3s8T5KhsL9z4","outputId":"6d1b90eb-b9ca-46c8-80d3-e1d06b97c1ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"uRgcHXc4Z-Zf"},"outputs":[{"name":"stderr","output_type":"stream","text":["The system cannot find the path specified.\n","The system cannot find the path specified.\n","'ngrok' is not recognized as an internal or external command,\n","operable program or batch file.\n","'pip' is not recognized as an internal or external command,\n","operable program or batch file.\n"]}],"source":["# 설치,  from, import\n","!pip install flask-ngrok > /dev/null 2>&1\n","!pip install pyngrok > /dev/null 2>&1\n","\n","# with open('drive/MyDrive/project/static/ngrok_auth.txt') as nf:\n","#     ngrok_auth = nf.read()\n","# !cat drive/MyDrive/project/static/ngrok_auth.txt \n","\n","!ngrok authtoken $ngrok_auth\n","!pip install efficientnet_pytorch"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2802,"status":"ok","timestamp":1661299940799,"user":{"displayName":"ᄋᄋ","userId":"14927427201019733620"},"user_tz":-540},"id":"TR3bQ66JaBOm"},"outputs":[],"source":["from flask import Flask, render_template, request\n","from flask_ngrok import run_with_ngrok\n","\n","# 웹- 업로드 시 실행하지 않게 미리 임폴트\n","import torchvision\n","from torchvision import transforms\n","import os\n","from torch.utils.data import Dataset,DataLoader\n","import torch"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"2cBsI-_9aDRd"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/scalp_weights/aram_model1.pt'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\인공지능사관학교\\Downloads\\sd\\(5)(o)8_23.sd.project.front.end.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%82%AC%EA%B4%80%ED%95%99%EA%B5%90/Downloads/sd/%285%29%28o%298_23.sd.project.front.end.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%82%AC%EA%B4%80%ED%95%99%EA%B5%90/Downloads/sd/%285%29%28o%298_23.sd.project.front.end.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# model load        \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%82%AC%EA%B4%80%ED%95%99%EA%B5%90/Downloads/sd/%285%29%28o%298_23.sd.project.front.end.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(PATH1, map_location\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%82%AC%EA%B4%80%ED%95%99%EA%B5%90/Downloads/sd/%285%29%28o%298_23.sd.project.front.end.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(PATH2, map_location\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%82%AC%EA%B4%80%ED%95%99%EA%B5%90/Downloads/sd/%285%29%28o%298_23.sd.project.front.end.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model3 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(PATH3, map_location\u001b[39m=\u001b[39mdevice)\n","File \u001b[1;32mc:\\Users\\인공지능사관학교\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n","File \u001b[1;32mc:\\Users\\인공지능사관학교\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n","File \u001b[1;32mc:\\Users\\인공지능사관학교\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/scalp_weights/aram_model1.pt'"]}],"source":["# 웹페이지에서 이미지를 업로드 받은 후 연산시간을 줄이기 위해 미리 로드하는 것\n","\n","# PATH\n","PATH1 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # 모델1\n","PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model2.pt'  # 모델2\n","PATH3 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model3.pt'  # 모델3\n","PATH4 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model4.pt'  # 모델4\n","PATH5 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model5.pt'  # 모델5\n","PATH6 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model6.pt'  # 모델6\n","\n","# cuda        \n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model load        \n","model1 = torch.load(PATH1, map_location=device)\n","model2 = torch.load(PATH2, map_location=device)\n","model3 = torch.load(PATH3, map_location=device)\n","model4 = torch.load(PATH4, map_location=device)\n","model5 = torch.load(PATH5, map_location=device)\n","model6 = torch.load(PATH6, map_location=device)\n","\n","# 아웃풋, 로스, 프레딕, 아큐러시\n","# 모델 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n","model1.eval() \n","model2.eval()\n","model3.eval()\n","model4.eval()\n","model5.eval()\n","model6.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2kRiC7aZamk","outputId":"82f53edd-ac51-4208-94f0-91f1d1ce5cb6"},"outputs":[{"name":"stdout","output_type":"stream","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"]},{"name":"stdout","output_type":"stream","text":[" * Running on http://d31c-34-70-115-176.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:12:51] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:12:52] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:12:55] \"\u001b[37mGET /menu HTTP/1.1\u001b[0m\" 200 -\n","100%|██████████| 1/1 [00:06<00:00,  6.97s/it]\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:13:09] \"\u001b[37mPOST /menu HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:13:09] \"\u001b[37mGET /upload/upload/upload.jpg?q=1661299982 HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:17:27] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:17:28] \"\u001b[37mGET /menu HTTP/1.1\u001b[0m\" 200 -\n","100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:17:35] \"\u001b[37mPOST /menu HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:17:35] \"\u001b[37mGET /upload/upload/upload.jpg?q=1661300254 HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:17:53] \"\u001b[37mGET /menu HTTP/1.1\u001b[0m\" 200 -\n","100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:18:02] \"\u001b[37mPOST /menu HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:18:02] \"\u001b[37mGET /upload/upload/upload.jpg?q=1661300281 HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:18:25] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:19:31] \"\u001b[37mGET /menu HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [24/Aug/2022 00:19:46] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"]}],"source":["## Web Server Code\n","app = Flask(__name__, static_folder='/content/drive/MyDrive/project/static/upload', # 이곳에 유저가 업로드한 파일을 save\n","                      template_folder='/content/drive/MyDrive/project/templates')\n","run_with_ngrok(app)\n","\n","@app.route('/')\n","def home():\n","    menu = {'home':1, 'menu':0}\n","    return render_template('index.html', menu=menu)\n","\n","@app.route('/menu', methods=['GET','POST'])\n","def menu():\n","    menu = {'home':0, 'menu':1}\n","    if request.method == 'GET':\n","        languages = [\n","            #{'disp':'영어', 'val':'en'},\n","            #{'disp':'일어', 'val':'jp'},\n","            #{'disp':'중국어', 'val':'cn'},\n","            #{'disp':'프랑스어', 'val':'fr'},\n","            #{'disp':'스페인어', 'val':'es'}\n","        ]\n","        \n","        #업로드폴더 리셋\n","        #upload_file_path = \"/content/drive/MyDrive/project/static/upload/upload/upload.jpg\"\n","        #if os.path.exists(upload_file_path):\n","        #    os.remove(upload_file_path) # 업로드폴더에 파일을삭제\n","\n","        return render_template('menu.html', menu=menu,\n","                                options=languages)   # 서버에서 클라이언트로 정보 전달\n","    else:\n","        # 사용자가 입력한 정보를 서버가 읽음\n","        # index = request.form['index']\n","        # lang = request.form['lang']\n","        # lyrics = request.form['lyrics']\n","        #print(lang, '\\n', index, '\\n', lyrics, sep='')\n","        # 사용자가 입력한 파일을 읽어서 upload 디렉토리에 저장\n","        f_image = request.files['image']\n","        fname = f_image.filename                # 사용자가 입력한 파일 이름\n","        newname = 'upload.jpg' # 업로드폴더를리셋하기위해일정한새이름을지정 upload.jpg로 업로드\n","        filename = os.path.join(app.static_folder, 'upload/') + newname  # 유저가 업로드한 사진이 저장되는 공간과 파일이름 \n","                                        # static_folder/upload 가 경로 파일네임 : fname 유저가 업로드한 파일의 이름 \n","        f_image.save(filename) #파일세이브\n","       \n","###########################################################################################################################################\n","\n","## model.test code\n","\n","# test 이미지파일 전처리, 텐서화\n","        # 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n","        transforms_test = transforms.Compose([     \n","                                                transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n","                                                transforms.ToTensor(),\n","                                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","                                            ])\n","        # root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n","        testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/project/static/upload' ,\n","                            transform = transforms_test)\n","      \n","# DataLoader를 통해 네트워크에 올리기 \n","        testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n","\n","        # correct = 0\n","        \n","        # 로스 연산\n","        # import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n","        # test_loss = 0\n","        \n","        from tqdm import tqdm # 진행률 표시를 위한\n","\n","        if __name__ == '__main__':\n","            with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n","                    for data, target in tqdm(testloader):                                   \n","                        data, target  = data.to(device), target.to(device) \n","                        \n","                        output1 = model1(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n","                        output2 = model2(data) \n","                        output3 = model3(data) \n","                        output4 = model4(data) \n","                        output5 = model5(data) \n","                        output6 = model6(data)\n","                 \n","# predict # # 0~3값만 뽑기 \n","        m1p = output1.argmax(dim=1, keepdim=True)[0][0].tolist()\n","        m2p = output2.argmax(dim=1, keepdim=True)[0][0].tolist()\n","        m3p = output3.argmax(dim=1, keepdim=True)[0][0].tolist()\n","        m4p = output4.argmax(dim=1, keepdim=True)[0][0].tolist()\n","        m5p = output5.argmax(dim=1, keepdim=True)[0][0].tolist()\n","        m6p = output6.argmax(dim=1, keepdim=True)[0][0].tolist()\n"," \n","# 진단\n","        d_list = [] # 두피유형진단\n","\n","        # 두피 유형 판단\n","        if m1p == 0 and m2p == 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n","            d1 = '정상입니다.'\n","            d_list.append(d1)\n","        elif m1p != 0 and m2p == 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n","            d2 = '건성 두피입니다.'\n","            d_list.append(d2)\n","        elif m1p == 0 and m2p != 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n","            d3 = '지성 두피입니다.'\n","            d_list.append(d3)\n","        elif m2p == 0 and m3p != 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n","            d4 = '민감성 두피입니다.'\n","            d_list.append(d4)\n","        elif m2p != 0 and m3p != 0 and m4p == 0 and m6p == 0 :\n","            d5 = '지루성 두피입니다.'\n","            d_list.append(d5)\n","        elif m3p == 0 and m4p != 0 and m6p == 0 :\n","            d6 = '염증성 두피입니다.'\n","            d_list.append(d6)\n","        elif m3p == 0 and m4p == 0 and m5p != 0 and m6p == 0 :\n","            d7 = '비듬성 두피입니다.'\n","            d_list.append(d7)\n","        elif m1p == 0 and m2p != 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p != 0 :\n","            d8 = '탈모입니다.'\n","            d_list.append(d8)\n","        else:\n","            d9 = '복합성 두피입니다.'\n","            d_list.append(d9)\n","\n","########################################################################################################################################\n"," \n","## Web Server Code\n","\n"," # 모델 실행후 결과를 돌려줌\n","        final = d_list[0] # 두피유형판단\n","        result = {'미세각질':m1p, '피지과다':m2p,'모낭사이홍반':m3p,'모낭홍반농포':m4p,'비듬':m5p,'탈모':m6p}\n","        final2 = '0:양호, 1:경증, 2:중등도, 3:중증' \n","        mtime = int(os.stat(filename).st_mtime) # 업로드한 시간값불러오기 > 큐변경 > 화면갱신 \n","\n","        #os.remove(\"/content/drive/MyDrive/project/static/upload/upload/4.jpg\") # 업로드폴더에업로드파일을삭제\n","        \n","\n","        return render_template('menu_res.html',  final2=final2,final=final, result=result, menu=menu,\n","                                fname=newname, mtime=mtime)\n","            \n","if __name__ == '__main__':\n","    app.run()\n","\n","# 코드간략"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPnID5Er5s8dA7M75Q/6EFO","collapsed_sections":[],"name":"(5)(o)8_23.sd.project.front.end.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.6"},"vscode":{"interpreter":{"hash":"ec04e5a75a06ece8df6d0a884439dd7612d7e5de7c7a13c71d3a8fb6369cc353"}}},"nbformat":4,"nbformat_minor":0}
